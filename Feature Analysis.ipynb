{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from node2vec import Node2Vec\n",
    "from node2vec.edges import HadamardEmbedder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition, datasets\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dirs():\n",
    "    dirs = []\n",
    "    for i in os.listdir('./data/'):\n",
    "        if os.path.isdir('./data/{}'.format(i)):\n",
    "            dirs.append(i)\n",
    "    return dirs\n",
    "\n",
    "\n",
    "def get_data(name,sep=','):\n",
    "    df = pd.DataFrame()\n",
    "    for x in get_dirs():\n",
    "        path = \"./data/{}/{}{}\".format(x, x, name)\n",
    "        temp = pd.read_csv(path,sep=sep)\n",
    "        df = df.append(temp)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d0</th>\n",
       "      <th>d1</th>\n",
       "      <th>d10</th>\n",
       "      <th>d11</th>\n",
       "      <th>d12</th>\n",
       "      <th>d13</th>\n",
       "      <th>d14</th>\n",
       "      <th>d15</th>\n",
       "      <th>d16</th>\n",
       "      <th>d17</th>\n",
       "      <th>...</th>\n",
       "      <th>d91</th>\n",
       "      <th>d92</th>\n",
       "      <th>d93</th>\n",
       "      <th>d94</th>\n",
       "      <th>d95</th>\n",
       "      <th>d96</th>\n",
       "      <th>d97</th>\n",
       "      <th>d98</th>\n",
       "      <th>d99</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.433656</td>\n",
       "      <td>-0.055179</td>\n",
       "      <td>1.183153</td>\n",
       "      <td>1.729102</td>\n",
       "      <td>1.273594</td>\n",
       "      <td>-2.215791</td>\n",
       "      <td>-0.500917</td>\n",
       "      <td>-0.767060</td>\n",
       "      <td>-0.313706</td>\n",
       "      <td>-0.863642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335375</td>\n",
       "      <td>1.470224</td>\n",
       "      <td>-1.193409</td>\n",
       "      <td>-0.720843</td>\n",
       "      <td>-0.112554</td>\n",
       "      <td>-0.535696</td>\n",
       "      <td>0.542414</td>\n",
       "      <td>0.863855</td>\n",
       "      <td>-0.312239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.124962</td>\n",
       "      <td>5.687909</td>\n",
       "      <td>2.437326</td>\n",
       "      <td>0.161104</td>\n",
       "      <td>0.010499</td>\n",
       "      <td>0.041381</td>\n",
       "      <td>0.298119</td>\n",
       "      <td>-0.034337</td>\n",
       "      <td>0.932403</td>\n",
       "      <td>4.823312</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.062720</td>\n",
       "      <td>-2.629499</td>\n",
       "      <td>0.212965</td>\n",
       "      <td>0.348428</td>\n",
       "      <td>0.044781</td>\n",
       "      <td>-0.399222</td>\n",
       "      <td>0.214164</td>\n",
       "      <td>1.121629</td>\n",
       "      <td>-0.925085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.672635</td>\n",
       "      <td>1.216574</td>\n",
       "      <td>0.017251</td>\n",
       "      <td>-0.637847</td>\n",
       "      <td>4.082369</td>\n",
       "      <td>-0.492336</td>\n",
       "      <td>2.507220</td>\n",
       "      <td>-0.010932</td>\n",
       "      <td>0.149649</td>\n",
       "      <td>1.464596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339615</td>\n",
       "      <td>1.204682</td>\n",
       "      <td>1.444797</td>\n",
       "      <td>2.332623</td>\n",
       "      <td>1.709905</td>\n",
       "      <td>-0.682997</td>\n",
       "      <td>-0.498459</td>\n",
       "      <td>1.138767</td>\n",
       "      <td>2.986296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.567257</td>\n",
       "      <td>-1.161251</td>\n",
       "      <td>0.054872</td>\n",
       "      <td>2.354262</td>\n",
       "      <td>-0.263919</td>\n",
       "      <td>1.357159</td>\n",
       "      <td>0.055553</td>\n",
       "      <td>0.552613</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>0.457668</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.445064</td>\n",
       "      <td>0.190531</td>\n",
       "      <td>-2.605351</td>\n",
       "      <td>0.963048</td>\n",
       "      <td>-0.072975</td>\n",
       "      <td>-0.372151</td>\n",
       "      <td>0.140691</td>\n",
       "      <td>0.148049</td>\n",
       "      <td>-0.353100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.154136</td>\n",
       "      <td>1.206412</td>\n",
       "      <td>0.206575</td>\n",
       "      <td>1.913312</td>\n",
       "      <td>-0.075497</td>\n",
       "      <td>-0.468258</td>\n",
       "      <td>0.208290</td>\n",
       "      <td>0.108401</td>\n",
       "      <td>-0.440274</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337241</td>\n",
       "      <td>0.600238</td>\n",
       "      <td>0.466132</td>\n",
       "      <td>1.253013</td>\n",
       "      <td>-1.682482</td>\n",
       "      <td>-0.636721</td>\n",
       "      <td>-0.002116</td>\n",
       "      <td>-1.544512</td>\n",
       "      <td>1.517065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         d0        d1       d10       d11       d12       d13       d14  \\\n",
       "0  5.433656 -0.055179  1.183153  1.729102  1.273594 -2.215791 -0.500917   \n",
       "1  0.124962  5.687909  2.437326  0.161104  0.010499  0.041381  0.298119   \n",
       "2  5.672635  1.216574  0.017251 -0.637847  4.082369 -0.492336  2.507220   \n",
       "3 -1.567257 -1.161251  0.054872  2.354262 -0.263919  1.357159  0.055553   \n",
       "4 -0.154136  1.206412  0.206575  1.913312 -0.075497 -0.468258  0.208290   \n",
       "\n",
       "        d15       d16       d17  ...       d91       d92       d93       d94  \\\n",
       "0 -0.767060 -0.313706 -0.863642  ...  0.335375  1.470224 -1.193409 -0.720843   \n",
       "1 -0.034337  0.932403  4.823312  ... -1.062720 -2.629499  0.212965  0.348428   \n",
       "2 -0.010932  0.149649  1.464596  ... -0.339615  1.204682  1.444797  2.332623   \n",
       "3  0.552613 -0.000304  0.457668  ... -1.445064  0.190531 -2.605351  0.963048   \n",
       "4  0.108401 -0.440274  0.199219  ... -0.337241  0.600238  0.466132  1.253013   \n",
       "\n",
       "        d95       d96       d97       d98       d99  label  \n",
       "0 -0.112554 -0.535696  0.542414  0.863855 -0.312239      1  \n",
       "1  0.044781 -0.399222  0.214164  1.121629 -0.925085      1  \n",
       "2  1.709905 -0.682997 -0.498459  1.138767  2.986296      1  \n",
       "3 -0.072975 -0.372151  0.140691  0.148049 -0.353100      1  \n",
       "4 -1.682482 -0.636721 -0.002116 -1.544512  1.517065      1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df = get_data('emb.csv.zip')\n",
    "emb_df = emb_df.drop(columns = ['Unnamed: 0'])\n",
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 82490 entries, 0 to 3595\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   is_dorm           82490 non-null  int64  \n",
      " 1   is_year           82490 non-null  int64  \n",
      " 2   year_diff         82490 non-null  float64\n",
      " 3   from_high_school  82490 non-null  int64  \n",
      " 4   to_high_school    82490 non-null  int64  \n",
      " 5   from_major        82490 non-null  int64  \n",
      " 6   to_major          82490 non-null  int64  \n",
      " 7   is_faculty        82490 non-null  int64  \n",
      " 8   is_gender         82490 non-null  int64  \n",
      " 9   label             82490 non-null  int64  \n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 6.9 MB\n"
     ]
    }
   ],
   "source": [
    "base_df = get_data('.raw_data',sep='\\t')\n",
    "base_df = base_df.drop(columns=['from_id','to_id'])\n",
    "base_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 82490 entries, 0 to 3595\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   preferential         82490 non-null  int64  \n",
      " 1   jaccard              82490 non-null  float64\n",
      " 2   adamic adar          82490 non-null  float64\n",
      " 3   resource allocation  82490 non-null  float64\n",
      " 4   is_dorm              82490 non-null  int64  \n",
      " 5   is_year              82490 non-null  int64  \n",
      " 6   year_diff            82490 non-null  float64\n",
      " 7   from_high_school     82490 non-null  int64  \n",
      " 8   to_high_school       82490 non-null  int64  \n",
      " 9   from_major           82490 non-null  int64  \n",
      " 10  to_major             82490 non-null  int64  \n",
      " 11  is_faculty           82490 non-null  int64  \n",
      " 12  is_gender            82490 non-null  int64  \n",
      " 13  label                82490 non-null  int64  \n",
      "dtypes: float64(4), int64(10)\n",
      "memory usage: 9.4 MB\n"
     ]
    }
   ],
   "source": [
    "top_df = get_data('.data',sep='\\t')\n",
    "top_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_dorm</th>\n",
       "      <th>is_year</th>\n",
       "      <th>year_diff</th>\n",
       "      <th>from_high_school</th>\n",
       "      <th>to_high_school</th>\n",
       "      <th>from_major</th>\n",
       "      <th>to_major</th>\n",
       "      <th>is_faculty</th>\n",
       "      <th>is_gender</th>\n",
       "      <th>d0</th>\n",
       "      <th>...</th>\n",
       "      <th>d91</th>\n",
       "      <th>d92</th>\n",
       "      <th>d93</th>\n",
       "      <th>d94</th>\n",
       "      <th>d95</th>\n",
       "      <th>d96</th>\n",
       "      <th>d97</th>\n",
       "      <th>d98</th>\n",
       "      <th>d99</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24005</td>\n",
       "      <td>50096</td>\n",
       "      <td>209</td>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.433656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335375</td>\n",
       "      <td>1.470224</td>\n",
       "      <td>-1.193409</td>\n",
       "      <td>-0.720843</td>\n",
       "      <td>-0.112554</td>\n",
       "      <td>-0.535696</td>\n",
       "      <td>0.542414</td>\n",
       "      <td>0.863855</td>\n",
       "      <td>-0.312239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2599</td>\n",
       "      <td>20823</td>\n",
       "      <td>208</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124962</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.062720</td>\n",
       "      <td>-2.629499</td>\n",
       "      <td>0.212965</td>\n",
       "      <td>0.348428</td>\n",
       "      <td>0.044781</td>\n",
       "      <td>-0.399222</td>\n",
       "      <td>0.214164</td>\n",
       "      <td>1.121629</td>\n",
       "      <td>-0.925085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9262</td>\n",
       "      <td>24568</td>\n",
       "      <td>208</td>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.672635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339615</td>\n",
       "      <td>1.204682</td>\n",
       "      <td>1.444797</td>\n",
       "      <td>2.332623</td>\n",
       "      <td>1.709905</td>\n",
       "      <td>-0.682997</td>\n",
       "      <td>-0.498459</td>\n",
       "      <td>1.138767</td>\n",
       "      <td>2.986296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>208</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.567257</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.445064</td>\n",
       "      <td>0.190531</td>\n",
       "      <td>-2.605351</td>\n",
       "      <td>0.963048</td>\n",
       "      <td>-0.072975</td>\n",
       "      <td>-0.372151</td>\n",
       "      <td>0.140691</td>\n",
       "      <td>0.148049</td>\n",
       "      <td>-0.353100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.522288</td>\n",
       "      <td>0</td>\n",
       "      <td>25996</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.154136</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337241</td>\n",
       "      <td>0.600238</td>\n",
       "      <td>0.466132</td>\n",
       "      <td>1.253013</td>\n",
       "      <td>-1.682482</td>\n",
       "      <td>-0.636721</td>\n",
       "      <td>-0.002116</td>\n",
       "      <td>-1.544512</td>\n",
       "      <td>1.517065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_dorm  is_year  year_diff  from_high_school  to_high_school  from_major  \\\n",
       "0        0        1   0.000000             24005           50096         209   \n",
       "1        0        1   0.000000              2599           20823         208   \n",
       "2        1        0   4.000000              9262           24568         208   \n",
       "3        0        1   0.000000                 0               0         202   \n",
       "4        1        0   1.522288                 0           25996           0   \n",
       "\n",
       "   to_major  is_faculty  is_gender        d0  ...       d91       d92  \\\n",
       "0       228           1          1  5.433656  ...  0.335375  1.470224   \n",
       "1       223           1          1  0.124962  ... -1.062720 -2.629499   \n",
       "2       228           1          1  5.672635  ... -0.339615  1.204682   \n",
       "3       208           1          1 -1.567257  ... -1.445064  0.190531   \n",
       "4       205           1          1 -0.154136  ... -0.337241  0.600238   \n",
       "\n",
       "        d93       d94       d95       d96       d97       d98       d99  label  \n",
       "0 -1.193409 -0.720843 -0.112554 -0.535696  0.542414  0.863855 -0.312239      1  \n",
       "1  0.212965  0.348428  0.044781 -0.399222  0.214164  1.121629 -0.925085      1  \n",
       "2  1.444797  2.332623  1.709905 -0.682997 -0.498459  1.138767  2.986296      1  \n",
       "3 -2.605351  0.963048 -0.072975 -0.372151  0.140691  0.148049 -0.353100      1  \n",
       "4  0.466132  1.253013 -1.682482 -0.636721 -0.002116 -1.544512  1.517065      1  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_emb_df = pd.concat([base_df.drop(columns=['label']),emb_df],axis=1)\n",
    "base_emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg(data, columns):\n",
    "    print('columns:', columns)\n",
    "    X = data[columns].values\n",
    "    y = data['label'].values\n",
    "    #X = normalize(X)\n",
    "    print(X.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    model = LogisticRegression(verbose=True,\n",
    "                               max_iter=100000).fit(X_train, y_train)\n",
    "    yhat = model.predict(X_test)\n",
    "    print(confusion_matrix(y_test, yhat))\n",
    "\n",
    "    print(classification_report(y_test, yhat))\n",
    "    print('ROC_AUC_SCORE:', roc_auc_score(y_test, yhat))\n",
    "    print('COEFF:', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(data, columns):\n",
    "    print('columns:', columns)\n",
    "    X = data[columns].values\n",
    "    y = data['label'].values\n",
    "    #X = normalize(X)\n",
    "    print(X.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    model = RandomForestClassifier(verbose=True).fit(X_train, y_train)\n",
    "    yhat = model.predict(X_test)\n",
    "    print(confusion_matrix(y_test, yhat))\n",
    "\n",
    "    print(classification_report(y_test, yhat))\n",
    "    print('ROC_AUC_SCORE:', roc_auc_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(data, columns):\n",
    "    print('columns:', columns)\n",
    "    X = data[columns].values\n",
    "    y = data['label'].values\n",
    "    X = normalize(X)\n",
    "    print(X.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    model = MLPClassifier(solver='lbfgs',\n",
    "                          hidden_layer_sizes=(100, 2)).fit(X_train, y_train)\n",
    "    yhat = [np.argmax(i) for i in (model.predict_proba(X_test))]\n",
    "    print(confusion_matrix(y_test, yhat))\n",
    "    print(classification_report(y_test, yhat))\n",
    "    print('ROC_AUC_SCORE:', roc_auc_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_red(df, columns, ind, normal=False):\n",
    "    # RANDOM SAMPLING\n",
    "    #df = df.iloc[ind, :]\n",
    "    X = df[list(columns)[:-1]]\n",
    "    y = df['label']\n",
    "    print(columns)\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Fit the scaler to the features and transform\n",
    "    val = X.values\n",
    "    if (normal):\n",
    "        val = normalize(X.values)\n",
    "    X_std = sc.fit_transform(val)\n",
    "    X_pca = decomposition.PCA(n_components=2).fit_transform(X_std)\n",
    "    X_tsne = TSNE(n_components=2).fit_transform(X_std)\n",
    "\n",
    "    X_true_pca = X_pca[np.where(y == 1)]\n",
    "    X_false_pca = X_pca[np.where(y == 0)]\n",
    "    X_true_tsne = X_tsne[np.where(y == 1)]\n",
    "    X_false_tsne = X_tsne[np.where(y == 0)]\n",
    "\n",
    "    plt.title('PCA')\n",
    "    plt.scatter(*X_true_pca.T, color='red', alpha=0.3)\n",
    "    plt.scatter(*X_false_pca.T, color='blue', alpha=0.3)\n",
    "    plt.show()\n",
    "    plt.title('TSNE')\n",
    "    plt.scatter(*X_true_tsne.T, color='red', alpha=0.3)\n",
    "    plt.scatter(*X_false_tsne.T, color='blue', alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = np.random.choice(emb_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_red(base_emb_df, list(base_emb_df.columns), ind=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Specs         Score\n",
      "1  from_high_school  1.186858e+07\n",
      "2    to_high_school  3.323767e+06\n",
      "3        from_major  3.342535e+04\n",
      "0         year_diff  2.112145e+04\n",
      "5        is_faculty  1.512449e+03\n",
      "6         is_gender  1.596437e+02\n",
      "4          to_major  4.727463e+01\n"
     ]
    }
   ],
   "source": [
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k='all')\n",
    "X = base_df.iloc[:,2:-1]  #independent columns\n",
    "y = base_df.iloc[:,-1]    #target column i.e price range\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-664012bd4b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#use inbuilt class feature_importances of tree based classifiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#plot graph of feature importances for better visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/link-env/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/link-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/link-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/link-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/link-env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/link-env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/link-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/link-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/link-env/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/link-env/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/link-env/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/link-env/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(a, order)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \"\"\"\n\u001b[0;32m--> 775\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;31m# Basic operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "X = base_df.iloc[:,2:-1]  #independent columns\n",
    "y = base_df.iloc[:,-1]    #target column i.e price range\n",
    "#get correlations of each features in dataset\n",
    "corrmat = base_df.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sns.heatmap(base_df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "X = top_df.iloc[:,:-1]  #independent columns\n",
    "y = top_df.iloc[:,-1]    #target column i.e price range\n",
    "#get correlations of each features in dataset\n",
    "corrmat = top_df.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sns.heatmap(top_df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_emb_df.iloc[:,:-1].values\n",
    "y = base_emb_df['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# Create first pipeline for base without reducing features.\n",
    "\n",
    "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "# pipe = Pipeline([('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Create param grid.\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear']},\n",
    "    {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10)),\n",
    "    'classifier__max_features' : list(range(6,32,5))}\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "#clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "#best_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_emb_df.iloc[:,:-1].values\n",
    "y = base_emb_df['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = LogisticRegression(verbose=True,max_iter=100000).fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "\n",
    "print(classification_report(y_test, yhat))\n",
    "print('ROC_AUC_SCORE:',roc_auc_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_emb_df.iloc[:,:-1].drop(columns=['year_diff']).values\n",
    "#print(X[:5])\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "y = base_emb_df['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = LogisticRegression(verbose=True,max_iter=100000).fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "\n",
    "print(classification_report(y_test, yhat))\n",
    "print('ROC_AUC_SCORE:',roc_auc_score(y_test, model.decision_function(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = emb_df.iloc[:,:-1].values\n",
    "#print(X[:5])\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "y = base_emb_df['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = LogisticRegression(verbose=True,max_iter=100000).fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "\n",
    "print(classification_report(y_test, yhat))\n",
    "print('ROC_AUC_SCORE:',roc_auc_score(y_test, model.decision_function(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = emb_df.iloc[:,:-1].values\n",
    "#print(X[:5])\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "y = base_emb_df['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = LogisticRegression(verbose=True,max_iter=100000).fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "\n",
    "print(classification_report(y_test, yhat))\n",
    "print('ROC_AUC_SCORE:',roc_auc_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_df.iloc[:,:-1].values\n",
    "#print(X[:5])\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "y = base_emb_df['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = LogisticRegression(verbose=True,max_iter=100000).fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "\n",
    "print(classification_report(y_test, yhat))\n",
    "print('ROC_AUC_SCORE:',roc_auc_score(y_test, model.decision_function(X_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = top_df.iloc[:, :-1].drop(columns=[\n",
    "    \"from_high_school\", \"to_high_school\", \"from_major\", \"year_diff\",\n",
    "    \"is_faculty\", \"is_gender\", \"to_major\"\n",
    "]).values\n",
    "#print(X[:5])\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "y = base_emb_df['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = LogisticRegression(verbose=True, max_iter=100000).fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "\n",
    "print(classification_report(y_test, yhat))\n",
    "print('ROC_AUC_SCORE:', roc_auc_score(y_test, model.decision_function(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(verbose=True).fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "\n",
    "print(classification_report(y_test, yhat))\n",
    "print('ROC_AUC_SCORE:',roc_auc_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_emb_df.iloc[:,:-1].drop(columns=['year_diff']).values\n",
    "#print(X[:5])\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "y = base_emb_df['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = LogisticRegression(C=4.281332398719396, class_weight=None, dual=False,\n",
    "                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                    max_iter=100, multi_class='auto', n_jobs=None, penalty='l1',\n",
    "                    random_state=None, solver='liblinear', tol=0.0001, verbose=1,\n",
    "                    warm_start=False).fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "\n",
    "print(classification_report(y_test, yhat))\n",
    "print('ROC_AUC_SCORE:',roc_auc_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(verbose=True).fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "\n",
    "print(classification_report(y_test, yhat))\n",
    "print('ROC_AUC_SCORE:',roc_auc_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_emb_df.iloc[:,:-1]\n",
    "y = base_emb_df['label']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train,y_train],axis=1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([X_test,y_test],axis=1)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('node2vec_train.csv.gz', compression='gzip',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('node2vec_test.csv.gz', compression='gzip',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:link-env] *",
   "language": "python",
   "name": "conda-env-link-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
