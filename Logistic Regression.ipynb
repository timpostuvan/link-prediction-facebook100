{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from node2vec import Node2Vec\n",
    "from node2vec.edges import HadamardEmbedder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition, datasets\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_dorm</th>\n",
       "      <th>is_year</th>\n",
       "      <th>year_diff</th>\n",
       "      <th>from_high_school</th>\n",
       "      <th>to_high_school</th>\n",
       "      <th>from_major</th>\n",
       "      <th>to_major</th>\n",
       "      <th>is_faculty</th>\n",
       "      <th>is_gender</th>\n",
       "      <th>d0</th>\n",
       "      <th>...</th>\n",
       "      <th>d59</th>\n",
       "      <th>d6</th>\n",
       "      <th>d60</th>\n",
       "      <th>d61</th>\n",
       "      <th>d62</th>\n",
       "      <th>d63</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17819</td>\n",
       "      <td>50093</td>\n",
       "      <td>265</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.586327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080709</td>\n",
       "      <td>0.663903</td>\n",
       "      <td>0.521325</td>\n",
       "      <td>-1.218457</td>\n",
       "      <td>0.572862</td>\n",
       "      <td>8.867662</td>\n",
       "      <td>0.098672</td>\n",
       "      <td>0.072862</td>\n",
       "      <td>1.136375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10070</td>\n",
       "      <td>24562</td>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.556291</td>\n",
       "      <td>...</td>\n",
       "      <td>2.682853</td>\n",
       "      <td>-0.022940</td>\n",
       "      <td>-0.371618</td>\n",
       "      <td>-0.987022</td>\n",
       "      <td>1.831474</td>\n",
       "      <td>-0.448014</td>\n",
       "      <td>1.167990</td>\n",
       "      <td>2.401762</td>\n",
       "      <td>0.431279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1544</td>\n",
       "      <td>6122</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.649554</td>\n",
       "      <td>...</td>\n",
       "      <td>6.857399</td>\n",
       "      <td>-0.348564</td>\n",
       "      <td>2.753245</td>\n",
       "      <td>-0.207652</td>\n",
       "      <td>1.892210</td>\n",
       "      <td>-0.977367</td>\n",
       "      <td>11.321891</td>\n",
       "      <td>2.510515</td>\n",
       "      <td>2.910005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.196375</td>\n",
       "      <td>1894</td>\n",
       "      <td>50410</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.757138</td>\n",
       "      <td>...</td>\n",
       "      <td>5.611234</td>\n",
       "      <td>-1.006211</td>\n",
       "      <td>-1.872412</td>\n",
       "      <td>-0.861397</td>\n",
       "      <td>0.114388</td>\n",
       "      <td>-1.096610</td>\n",
       "      <td>-4.892152</td>\n",
       "      <td>-3.294941</td>\n",
       "      <td>0.133597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3535</td>\n",
       "      <td>21037</td>\n",
       "      <td>238</td>\n",
       "      <td>271</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.290842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824280</td>\n",
       "      <td>0.429348</td>\n",
       "      <td>2.083774</td>\n",
       "      <td>0.281935</td>\n",
       "      <td>-1.777484</td>\n",
       "      <td>0.258835</td>\n",
       "      <td>0.234619</td>\n",
       "      <td>-0.287869</td>\n",
       "      <td>2.079238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_dorm  is_year  year_diff  from_high_school  to_high_school  from_major  \\\n",
       "0        0        0   1.000000             17819           50093         265   \n",
       "1        0        1   0.000000             10070           24562          51   \n",
       "2        0        1   0.000000              1544            6122          14   \n",
       "3        0        0   2.196375              1894           50410           0   \n",
       "4        0        1   0.000000              3535           21037         238   \n",
       "\n",
       "   to_major  is_faculty  is_gender        d0  ...       d59        d6  \\\n",
       "0       294           1          1  0.586327  ...  0.080709  0.663903   \n",
       "1        60           1          1  1.556291  ...  2.682853 -0.022940   \n",
       "2        39           1          1 -0.649554  ...  6.857399 -0.348564   \n",
       "3        40           0          0  3.757138  ...  5.611234 -1.006211   \n",
       "4       271           1          1  1.290842  ...  0.824280  0.429348   \n",
       "\n",
       "        d60       d61       d62       d63         d7        d8        d9  \\\n",
       "0  0.521325 -1.218457  0.572862  8.867662   0.098672  0.072862  1.136375   \n",
       "1 -0.371618 -0.987022  1.831474 -0.448014   1.167990  2.401762  0.431279   \n",
       "2  2.753245 -0.207652  1.892210 -0.977367  11.321891  2.510515  2.910005   \n",
       "3 -1.872412 -0.861397  0.114388 -1.096610  -4.892152 -3.294941  0.133597   \n",
       "4  2.083774  0.281935 -1.777484  0.258835   0.234619 -0.287869  2.079238   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './data/'\n",
    "emb_data_train = pd.read_csv('./data/node2vec_v2_train.csv.gz',\n",
    "                             compression='gzip',\n",
    "                             sep='\\t')\n",
    "emb_data_test = pd.read_csv('./data/node2vec_v2_test.csv.gz',\n",
    "                            compression='gzip',\n",
    "                            sep='\\t')\n",
    "emb_data_train = emb_data_train.drop(columns=['Unnamed: 0'])\n",
    "emb_data_test = emb_data_test.drop(columns=['Unnamed: 0'])\n",
    "emb_data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg(data, test, params={}, cols=[], model=False):\n",
    "    cols.append('label')\n",
    "    X = data.drop(columns=cols).values\n",
    "    y = data['label'].values\n",
    "    X_test = test.drop(columns=cols).values\n",
    "    y_test = test['label'].values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    print('X:', X.shape)\n",
    "    model = LogisticRegression(**params).fit(X, y)\n",
    "    yhat = model.predict(X_test)\n",
    "    print(confusion_matrix(y_test, yhat))\n",
    "    print(classification_report(y_test, yhat))\n",
    "    print('ROC_AUC_SCORE:',\n",
    "          roc_auc_score(y_test, model.decision_function(X_test)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_data(cols):\n",
    "\n",
    "    emb_data_train = pd.read_csv('./data/node2vec_v2_train.csv.gz',\n",
    "                                 compression='gzip',\n",
    "                                 sep='\\t')\n",
    "    emb_data_test = pd.read_csv('./data/node2vec_v2_test.csv.gz',\n",
    "                                compression='gzip',\n",
    "                                sep='\\t')\n",
    "    emb_data_train = emb_data_train.drop(columns=['Unnamed: 0'])\n",
    "    emb_data_test = emb_data_test.drop(columns=['Unnamed: 0'])\n",
    "    params = {\n",
    "        'C': 150,  #100,\n",
    "        'class_weight': None,\n",
    "        'dual': False,\n",
    "        'fit_intercept': True,\n",
    "        'intercept_scaling': 1,\n",
    "        'l1_ratio': None,\n",
    "        'max_iter': 100000,\n",
    "        'multi_class': 'auto',\n",
    "        'n_jobs': None,\n",
    "        'penalty': 'l1',\n",
    "        'random_state': None,\n",
    "        'solver': 'liblinear',\n",
    "        'tol': 0.0001,\n",
    "        'verbose': 1,\n",
    "        'warm_start': False\n",
    "    }\n",
    "    return LogReg(emb_data_train,\n",
    "                  emb_data_test,\n",
    "                  params,\n",
    "                  cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncols = [\"is_dorm\",\"is_year\",\"year_diff\", \"from_high_school\",\\n            \"to_high_school\", \"from_major\", \"to_major\", \"is_faculty\",\\n            \"is_gender\",\\'label\\']\\nX =  emb_data_train.drop(columns=cols).values\\ny = emb_data_train[\\'label\\'].values\\n\\nscaler = MinMaxScaler(feature_range = (0,1))\\nscaler.fit(X)\\nX = scaler.transform(X)\\n# Create regularization penalty space\\npenalty = [\\'l1\\', \\'l2\\']\\n\\n# Create regularization hyperparameter space\\nC = [0.001,0.1,1,10,100]\\n# Get solver\\nsolver = [\\'liblinear\\']\\n# Create hyperparameter options\\nhyperparameters = dict(C=C, penalty=penalty,solver=solver)\\n# Create grid search using 5-fold cross validation\\nclf = GridSearchCV(LogisticRegression(max_iter=100000), hyperparameters, cv=5, verbose=True,n_jobs=-1)\\n# Fit grid search\\nbest_model = clf.fit(X, y)\\n# View best hyperparameters\\n\\nprint(\\'PARAMS:\\', best_model.best_estimator_.get_params())\\nparams = best_model.best_estimator_.get_params() \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cols = [\"is_dorm\",\"is_year\",\"year_diff\", \"from_high_school\",\n",
    "            \"to_high_school\", \"from_major\", \"to_major\", \"is_faculty\",\n",
    "            \"is_gender\",'label']\n",
    "X =  emb_data_train.drop(columns=cols).values\n",
    "y = emb_data_train['label'].values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = [0.001,0.1,1,10,100]\n",
    "# Get solver\n",
    "solver = ['liblinear']\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty,solver=solver)\n",
    "# Create grid search using 5-fold cross validation\n",
    "clf = GridSearchCV(LogisticRegression(max_iter=100000), hyperparameters, cv=5, verbose=True,n_jobs=-1)\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X, y)\n",
    "# View best hyperparameters\n",
    "\n",
    "print('PARAMS:', best_model.best_estimator_.get_params())\n",
    "params = best_model.best_estimator_.get_params() \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'C': 150,  #100,\n",
    "    'class_weight': None,\n",
    "    'dual': False,\n",
    "    'fit_intercept': True,\n",
    "    'intercept_scaling': 1,\n",
    "    'l1_ratio': None,\n",
    "    'max_iter': 100000,\n",
    "    'multi_class': 'auto',\n",
    "    'n_jobs': None,\n",
    "    'penalty': 'l1',\n",
    "    'random_state': None,\n",
    "    'solver': 'liblinear',\n",
    "    'tol': 0.0001,\n",
    "    'verbose': 1,\n",
    "    'warm_start': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unseen_emb_data():\n",
    "    cols = [\n",
    "        \"is_dorm\", \"is_year\", \"year_diff\", \"from_high_school\",\n",
    "        \"to_high_school\", \"from_major\", \"to_major\", \"is_faculty\", \"is_gender\",'label'\n",
    "    ]\n",
    "    \n",
    "    unseen = pd.read_csv('./unseen-data/node2vec_v2_data.csv.gz',\n",
    "                         compression='gzip',\n",
    "                         sep='\\t')\n",
    "    X_test = unseen.drop(columns=cols).values\n",
    "    y_test = unseen[['label']].values\n",
    "    model = emb_data([\n",
    "        \"is_dorm\", \"is_year\", \"year_diff\", \"from_high_school\",\n",
    "        \"to_high_school\", \"from_major\", \"to_major\", \"is_faculty\", \"is_gender\"\n",
    "    ])\n",
    "    yhat = model.predict(X_test)\n",
    "    print(confusion_matrix(y_test, yhat))\n",
    "    print(classification_report(y_test, yhat))\n",
    "    print('ROC_AUC_SCORE:',\n",
    "          roc_auc_score(y_test, model.decision_function(X_test)))\n",
    "    print('MODEL SUMMARY:',model.intercept_, model.coef_)\n",
    "    print('MODEL SUMMARY:',unseen.columns)   \n",
    "    print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_data():\n",
    "    train = pd.read_csv('./data/baseline_train_filtered.data', sep='\\t')\n",
    "    test = pd.read_csv('./data/baseline_test_filtered.data', sep='\\t')\n",
    "    return LogReg(train,\n",
    "                  test,\n",
    "                  params={\n",
    "                      'max_iter': 100000,\n",
    "                      'solver': 'liblinear'\n",
    "                  },\n",
    "                  cols=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unseen_base_data():\n",
    "    unseen = pd.read_csv('./unseen-data/baseline_unseen_filtered.data',\n",
    "                         sep='\\t')\n",
    "    X_test = unseen.drop(columns=['label']).values\n",
    "    y_test = unseen[['label']].values\n",
    "    model = baseline_data()\n",
    "    yhat = model.predict(X_test)\n",
    "    print(confusion_matrix(y_test, yhat))\n",
    "    print(classification_report(y_test, yhat))\n",
    "    print('ROC_AUC_SCORE:',\n",
    "          roc_auc_score(y_test, model.decision_function(X_test)))\n",
    "    print('MODEL SUMMARY:',model.intercept_, model.coef_)\n",
    "    print('MODEL SUMMARY:',unseen.columns)   \n",
    "    print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_data():\n",
    "    train = pd.read_csv('./data/topological_train_filtered.data', sep='\\t')\n",
    "    test = pd.read_csv('./data/topological_train_filtered.data', sep='\\t')\n",
    "    params = {\n",
    "    'C': 0.001,  #100,\n",
    "    'class_weight': None,\n",
    "    'dual': False,\n",
    "    'fit_intercept': True,\n",
    "    'intercept_scaling': 1,\n",
    "    'l1_ratio': None,\n",
    "    'max_iter': 100000,\n",
    "    'multi_class': 'auto',\n",
    "    'n_jobs': None,\n",
    "    'penalty': 'l1',\n",
    "    'random_state': None,\n",
    "    'solver': 'liblinear',\n",
    "    'tol': 0.0001,\n",
    "    'verbose': 1,\n",
    "    'warm_start': False\n",
    "}\n",
    "    return LogReg(train,\n",
    "                  test,\n",
    "                  params=params,\n",
    "                  cols=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unseen_top_data():\n",
    "    unseen = pd.read_csv('./unseen-data/topological_unseen_filtered.data',\n",
    "                         sep='\\t')\n",
    "    X_test = unseen.drop(columns=['label']).values\n",
    "    y_test = unseen[['label']].values\n",
    "    model = top_data()\n",
    "    yhat = model.predict(X_test)\n",
    "    print(confusion_matrix(y_test, yhat))\n",
    "    print(classification_report(y_test, yhat))\n",
    "    print('ROC_AUC_SCORE:',\n",
    "          roc_auc_score(y_test, model.decision_function(X_test)))\n",
    "    print('MODEL SUMMARY:',model.intercept_, model.coef_)\n",
    "    print('MODEL SUMMARY:',unseen.columns)   \n",
    "    print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (65992, 3)\n",
      "[[4960 3261]\n",
      " [  89 8188]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.60      0.75      8221\n",
      "         1.0       0.72      0.99      0.83      8277\n",
      "\n",
      "    accuracy                           0.80     16498\n",
      "   macro avg       0.85      0.80      0.79     16498\n",
      "weighted avg       0.85      0.80      0.79     16498\n",
      "\n",
      "ROC_AUC_SCORE: 0.940153589340453\n",
      "[[ 6994  7083]\n",
      " [   89 13988]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.50      0.66     14077\n",
      "         1.0       0.66      0.99      0.80     14077\n",
      "\n",
      "    accuracy                           0.75     28154\n",
      "   macro avg       0.83      0.75      0.73     28154\n",
      "weighted avg       0.83      0.75      0.73     28154\n",
      "\n",
      "ROC_AUC_SCORE: 0.9263814594780213\n",
      "MODEL SUMMARY: [-2.23955102] [[35.12658717 24.55445738  8.74795957]]\n",
      "MODEL SUMMARY: Index(['jaccard', 'adamic adar', 'resource allocation', 'label'], dtype='object')\n",
      "[1.65714286e-01 2.05347969e+02 4.81100000e+03]\n"
     ]
    }
   ],
   "source": [
    "unseen_base_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (61867, 64)\n",
      "[LibLinear][[9375  997]\n",
      " [1703 8548]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87     10372\n",
      "           1       0.90      0.83      0.86     10251\n",
      "\n",
      "    accuracy                           0.87     20623\n",
      "   macro avg       0.87      0.87      0.87     20623\n",
      "weighted avg       0.87      0.87      0.87     20623\n",
      "\n",
      "ROC_AUC_SCORE: 0.9365540156119203\n",
      "[[12680  1397]\n",
      " [ 2966 11111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85     14077\n",
      "           1       0.89      0.79      0.84     14077\n",
      "\n",
      "    accuracy                           0.85     28154\n",
      "   macro avg       0.85      0.85      0.84     28154\n",
      "weighted avg       0.85      0.85      0.84     28154\n",
      "\n",
      "ROC_AUC_SCORE: 0.9229366201819724\n",
      "MODEL SUMMARY: [-93.21034384] [[3.67365969 4.00910664 2.74101355 4.37771168 4.38297982 4.06522574\n",
      "  3.54705141 3.65401041 3.62687741 3.41746633 4.10202749 2.78892985\n",
      "  4.80832674 4.90522543 3.27526404 2.98857176 3.26658188 4.13117699\n",
      "  5.23521164 4.23583165 3.08554868 3.18010654 3.59218346 2.86106401\n",
      "  2.94255244 4.25274587 4.44727762 3.58123305 4.28025277 4.30551768\n",
      "  3.77422635 3.1466204  2.58518673 3.89717492 3.53638345 2.50790712\n",
      "  3.42490717 4.39772929 3.84856416 4.52819717 3.53461688 3.64972889\n",
      "  2.94791915 2.01200518 3.25076557 3.4191493  4.5096645  3.45811005\n",
      "  2.63798993 3.34602256 3.92785732 2.55761469 3.51080999 3.58727192\n",
      "  2.76182601 3.26171376 4.0008114  3.61119616 3.34136017 3.02526\n",
      "  3.36105949 2.62432335 4.24093024 2.5750966 ]]\n",
      "MODEL SUMMARY: Index(['is_dorm', 'is_year', 'year_diff', 'from_high_school', 'to_high_school',\n",
      "       'from_major', 'to_major', 'is_faculty', 'is_gender', 'd0', 'd1', 'd10',\n",
      "       'd11', 'd12', 'd13', 'd14', 'd15', 'd16', 'd17', 'd18', 'd19', 'd2',\n",
      "       'd20', 'd21', 'd22', 'd23', 'd24', 'd25', 'd26', 'd27', 'd28', 'd29',\n",
      "       'd3', 'd30', 'd31', 'd32', 'd33', 'd34', 'd35', 'd36', 'd37', 'd38',\n",
      "       'd39', 'd4', 'd40', 'd41', 'd42', 'd43', 'd44', 'd45', 'd46', 'd47',\n",
      "       'd48', 'd49', 'd5', 'd50', 'd51', 'd52', 'd53', 'd54', 'd55', 'd56',\n",
      "       'd57', 'd58', 'd59', 'd6', 'd60', 'd61', 'd62', 'd63', 'd7', 'd8', 'd9',\n",
      "       'label'],\n",
      "      dtype='object')\n",
      "[-1.85220912e-01  6.88276231e-01 -2.14094996e-01 -1.02154352e-01\n",
      "  5.32522976e-01  4.28259552e-01  6.79920852e-01 -6.82004035e-01\n",
      " -2.95008945e+00  8.46614391e-02 -6.75085816e-04  8.38648915e-01\n",
      "  5.95304742e-02 -2.67355055e-01 -8.96047503e-02 -6.57389879e-01\n",
      " -2.83261031e-01  2.54914284e-01 -6.83657527e-02 -1.69251617e-02\n",
      "  1.49748966e-01 -1.65851808e+00 -1.02083802e-01  4.92137298e-02\n",
      " -1.77095485e+00  2.91976761e-02 -3.11001539e-01  4.26764637e-01\n",
      "  2.94103593e-01 -2.39928341e+00 -2.52972460e+00  4.86783952e-01\n",
      "  7.33935833e-02 -1.96687996e-01  1.23532815e-02  1.77492723e-02\n",
      " -4.21522349e-01 -1.20642543e-01 -5.39932191e-01 -1.10969579e+00\n",
      " -2.49358580e-01 -2.50994980e-01 -6.71299696e-01 -9.03281748e-01\n",
      " -4.18585464e-02  8.65788341e-01  1.30084276e-01 -4.09488499e-01\n",
      "  1.69590160e-01  1.19733453e+00  2.46567279e-01 -5.63598275e-01\n",
      " -7.96192050e-01 -8.09689641e-01  1.20156985e-02 -1.52786762e-01\n",
      "  2.65000224e-01 -3.54604220e+00 -5.98338008e-01  1.94278395e+00\n",
      " -2.36864910e-01  7.94898629e-01 -1.44525960e-01 -4.18812990e-01]\n"
     ]
    }
   ],
   "source": [
    "unseen_emb_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (65992, 9)\n",
      "[LibLinear][[18261 14763]\n",
      " [  235 32733]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.55      0.71     33024\n",
      "         1.0       0.69      0.99      0.81     32968\n",
      "\n",
      "    accuracy                           0.77     65992\n",
      "   macro avg       0.84      0.77      0.76     65992\n",
      "weighted avg       0.84      0.77      0.76     65992\n",
      "\n",
      "ROC_AUC_SCORE: 0.9570162918177703\n",
      "[[ 6507  7570]\n",
      " [   66 14011]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.46      0.63     14077\n",
      "         1.0       0.65      1.00      0.79     14077\n",
      "\n",
      "    accuracy                           0.73     28154\n",
      "   macro avg       0.82      0.73      0.71     28154\n",
      "weighted avg       0.82      0.73      0.71     28154\n",
      "\n",
      "ROC_AUC_SCORE: 0.9478721818457874\n",
      "MODEL SUMMARY: [-0.58921265] [[0.         0.         4.58826673 0.         0.18697671 1.18756978\n",
      "  0.         0.         0.03495417]]\n",
      "MODEL SUMMARY: Index(['preferential', 'jaccard', 'adamic adar', 'resource allocation',\n",
      "       'is_dorm', 'is_year', 'from_major', 'to_major', 'is_faculty', 'label'],\n",
      "      dtype='object')\n",
      "[1.03550000e+04 1.65714286e-01 2.05347969e+02 4.81100000e+03\n",
      " 0.00000000e+00 1.00000000e+00 3.14000000e+02 3.24000000e+02\n",
      " 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "unseen_top_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:link-env] *",
   "language": "python",
   "name": "conda-env-link-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
